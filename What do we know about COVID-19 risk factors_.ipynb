{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we know about COVID-19 risk factors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** Create an unsupervised scientific literature understanding system that can take in common terms and analyze a very large corpus of scientific papers and return highly relevant text excerpts from papers containing topical data relating to the common text inputed, allowing a single researcher or small team to gather targeted information and quickly and easily locate relevant text in the scientific papers to answer important questions about the new virus from a large corpus of documents.\n",
    "\n",
    "**APPROACH:** The current implementation uses Pandas built in search technology to search all paper abstracts for the keywords realting to topics where specific answers are desired.  Once the dataframe slice is returned, the abstracts are then parsed into sentence and word levels to understand which of the abstracts likley contain the most relevant answers to the keyword topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the notebook to browser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import functools\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210537, 7)\n",
      "(70059, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>no data provided</td>\n",
       "      <td>Latest assessment on COVID-19 from the Europea...</td>\n",
       "      <td>10.2807/1560-7917.es.2020.25.8.2002271</td>\n",
       "      <td>no data providedlatest assessment on covid-19 ...</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>no data provided</td>\n",
       "      <td>Euro Surveill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>no data provided</td>\n",
       "      <td>Updated rapid risk assessment from ECDC on the...</td>\n",
       "      <td>10.2807/1560-7917.es.2020.25.9.2003051</td>\n",
       "      <td>no data providedupdated rapid risk assessment ...</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>no data provided</td>\n",
       "      <td>Euro Surveill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>no data provided</td>\n",
       "      <td>Updated rapid risk assessment from ECDC on the...</td>\n",
       "      <td>10.2807/1560-7917.es.2020.25.10.2003121</td>\n",
       "      <td>no data providedupdated rapid risk assessment ...</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>no data provided</td>\n",
       "      <td>Euro Surveill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sha                                              title  \\\n",
       "4661  no data provided  Latest assessment on COVID-19 from the Europea...   \n",
       "4697  no data provided  Updated rapid risk assessment from ECDC on the...   \n",
       "4731  no data provided  Updated rapid risk assessment from ECDC on the...   \n",
       "\n",
       "                                          doi  \\\n",
       "4661   10.2807/1560-7917.es.2020.25.8.2002271   \n",
       "4697   10.2807/1560-7917.es.2020.25.9.2003051   \n",
       "4731  10.2807/1560-7917.es.2020.25.10.2003121   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "4661  no data providedlatest assessment on covid-19 ...   2020-02-27   \n",
       "4697  no data providedupdated rapid risk assessment ...   2020-03-05   \n",
       "4731  no data providedupdated rapid risk assessment ...   2020-03-12   \n",
       "\n",
       "               authors        journal  \n",
       "4661  no data provided  Euro Surveill  \n",
       "4697  no data provided  Euro Surveill  \n",
       "4731  no data provided  Euro Surveill  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the meta data from the CSV file using 3 columns (abstract, title, authors),\n",
    "df=pd.read_csv('../metadata.csv', usecols=['title','journal','abstract','authors','doi','publish_time','sha'], low_memory=False)\n",
    "print(df.shape)\n",
    "\n",
    "#fill na fields\n",
    "df=df.fillna('no data provided')\n",
    "\n",
    "#drop duplicate titles\n",
    "df = df.drop_duplicates(subset='title', keep=\"first\")\n",
    "\n",
    "#keep only 2020 dated papers\n",
    "df=df[df['publish_time'].str.contains('2020')]\n",
    "\n",
    "# convert abstracts to lowercase\n",
    "df[\"abstract\"] = df[\"abstract\"].str.lower()+df[\"title\"].str.lower()\n",
    "\n",
    "#show 3 lines of the new dataframe\n",
    "df=search_focus(df)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only documents with covid -cov-2 and cov2\n",
    "def search_focus(df):\n",
    "    dfa = df[df['abstract'].str.contains('covid')]\n",
    "    dfb = df[df['abstract'].str.contains('-cov-2')]\n",
    "    dfc = df[df['abstract'].str.contains('cov2')]\n",
    "    dfd = df[df['abstract'].str.contains('ncov')]\n",
    "    frames=[dfa,dfb,dfc,dfd]\n",
    "    df = pd.concat(frames)\n",
    "    df=df.drop_duplicates(subset='title', keep=\"first\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# function to stem keywords into a common base word\n",
    "def stem_words(words):\n",
    "    stemmer = PorterStemmer()\n",
    "    singles=[]\n",
    "    for w in words:\n",
    "        singles.append(stemmer.stem(w))\n",
    "    return singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists for topic words realting to tasks\n",
    "tasks = [['comorbidities','comorbid'],['risk factor','risk factors'],['cancer patient', 'cancer patients'],['hypertension','hyperten'],['heart', 'disease'],['chronic', 'bronchitis'],['cerebral', 'infarction'],['diabetes', 'diabete'],['copd','copd'],[\"blood type\",\"type\"],['smoking','smok'],['basic','reproductive','number'],[\"incubation\", \"period\", \"days\"]]\n",
    "\n",
    "z=0\n",
    "for terms in tasks:\n",
    "    stra=' '\n",
    "    stra=' '.join(terms)\n",
    "    k=str(z)\n",
    "    z=z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Task Topic: comorbidities comorbid</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'HTML' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ac964ce3c83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mdf_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m#display(df_table)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mdf_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'HTML' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# loop through the list of lists\n",
    "z=0\n",
    "for search_words in tasks:\n",
    "    df_table = pd.DataFrame(columns = [\"pub_date\",\"authors\",\"title\",\"excerpt\"])\n",
    "    str1=''\n",
    "    # make a string of the search words to print readable search\n",
    "    str1=' '.join(search_words)\n",
    "    dfa=df[functools.reduce(lambda a, b: a&b, (df['abstract'].str.contains(s) for s in search_words))]\n",
    "    df1=dfa.drop_duplicates()\n",
    "    \n",
    "    display(HTML('<h3>Task Topic: '+str1+'</h3>'))\n",
    "    #tell the system how many sentences are needed\n",
    "    max_sentences=5\n",
    "\n",
    "    z=z+1\n",
    "    # record how many sentences have been saved for display\n",
    "    # loop through the result of the dataframe search\n",
    "    for index, row in df1.iterrows():\n",
    "        pub_sentence=''\n",
    "        sentences_used=0\n",
    "        #break apart the absracrt to sentence level\n",
    "        sentences = row['abstract'].split('. ')\n",
    "        \n",
    "        #loop through the sentences of the abstract\n",
    "        for sentence in sentences:\n",
    "            # missing lets the system know if all the words are in the sentence\n",
    "            missing=0\n",
    "            #loop through the words of sentence\n",
    "            for word in search_words:\n",
    "                #if keyword missing change missing variable\n",
    "                if word not in sentence:\n",
    "                    missing=missing+1\n",
    "            # after all sentences processed show the sentences not missing keywords limit to max_sentences\n",
    "            if missing < len(search_words)-1 and sentences_used < max_sentences and len(sentence)<1000 and sentence!='':\n",
    "                sentence=sentence.capitalize()\n",
    "                if sentence[len(sentence)-1]!='.':\n",
    "                    sentence=sentence+'.'\n",
    "                pub_sentence=pub_sentence+'<br><br>'+sentence\n",
    "                \n",
    "        if pub_sentence!='':\n",
    "            sentence=pub_sentence\n",
    "            sentences_used=sentences_used+1\n",
    "            authors=row[\"authors\"].split(\" \")\n",
    "            link=row['doi']\n",
    "            title=row[\"title\"]\n",
    "            linka='https://doi.org/'+link\n",
    "            linkb=title\n",
    "            sentence='<p align=\"left\">'+sentence+'</p>'\n",
    "            final_link='<p align=\"left\"><a href=\"{}\">{}</a></p>'.format(linka,linkb)\n",
    "            to_append = [row['publish_time'],authors[0]+' et al.',final_link,sentence]\n",
    "            df_length = len(df_table)\n",
    "            df_table.loc[df_length] = to_append\n",
    "            \n",
    "    filename=str1+'.csv'\n",
    "    df_table.to_csv(filename,index = False)\n",
    "    df_table=HTML(df_table.to_html(escape=False,index=False))\n",
    "    display(df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
